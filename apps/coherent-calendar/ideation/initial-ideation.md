# Coherent Calendar: Initial Ideation

Ideating on app for Calendar Cohering. This is speaking to some of my personal needs for tending to a community calendar, as well as a system that will support Boulder.earth and their needs, and ideally expand to support many different community networks. A calendar for Boulder.Builders, a calendar for curating writing events in Boulder, other systems...
Some aspect of this will involve crawling various sites and bringing all of the events in an area into one database, and then some system for filtering them well to create different views.
There is also an element of this that involves being able to quickly scrape an individual page.
I was also thinking about the bit of this that could involve a bit of a tinder-like interface, for people to vote on what events they particularly like.

Ok so I always discover more through conversation. Caitlin was just talking about needing a better system for discovering events in and around Boulder and I spoke of what I am doing.

The first part is super resonant and easy to use; find where events are posted such as junkyard social, the dairy, trident, and other places; and scrape all of these and bring them into one database. Then make them easily searchable so that the events that are most relevant to you can get easily surfaced. This feels doable.

Another part is the bit that gets events out of a community telegram chat (or ideally other community chats as well) through some kind of simple interface to post a URL and add it to the calendar. The bit of this that feels relevant in v1 is just the ability to add individual events by posting the URL with the ability to cross-check its accuracy and make manual corrections or even manually post events details. A key factor is being able to ensure no duplicates in the event.

So what's the core app we want to build to start:

There should be an admin interface where different event sources are posted; things like junkyardsocial.com/events; direct pages where events are linked. The system should then do a pass over the page to understand the layout of the page and make guesses as to the best approach to getting all of the events from the page, such as iterating through pages, clicking through different links, etc...; it should then output this as a page strategy and it should attempt the strategy. If there are any problems, the user (admin) should be able to give feedback about the strategy to help the system adapt and make any appropriate adjustments.
Each event page should have a given cadence for how often the system checks this page. By default, most of these pages we'll just check once a week, with the option to manually refresh. Also definitely something to explore in terms of how far back we want to get events; probably by default we stop after 1 month ahead.
So the admins panel will show a list of event sources, then you will be able to view events that came from that source, and you will be able to see the custom prompts for getting events from that page; and admins will also be able to refine the prompt (through an AI dialogue).
The admin panel will also have the option of posting a specific event link. For each event page, everyone will be able to see the link where it came from and the information that was scraped from the page; and admins will be able to manually update any information; if information is manually updated admins will be able to add a note to say what was wrong and to make any guesses as to how to fix it. Then whenever the admin is viewing the event sources, they can ask the system to adjust the algorithm and they will be able to use feedback that was given to help adjust.
The system should also have custom prompts for not just event sources, but also for given URL schemas. So for example, anything coming from meetup.com should be able to have custom prompting, that helps ensure individual pages are able to be scraped well.
Ideally the system scraper has agentic capacities that can make calls to various different systems for how to scrape. So for some websites, it will be necessary to load the page up for JS with something like puppeteer, perhaps it just makes sense to do this for everything. Some websites like Facebook might also require some more custom code, so it should be possible for the agent to be able to make a custom call; even if it requires extra functionality to be coded on the backend.

All users should be able to see the database of events, and see what source it came from; and they should probably be able to also see how the event was sourced. There really shouldn't be much of an issue with information being viewable, although we do want to ensure that users have a simple and easy interface that doesn't overwhelm them with info; so extra stuff should be put on deeper layers or something. We can strategize about this.

The primary interface for users is being able to see the database of events and being able to search it and filter it. Ideally the system should dynamically create tags/categories which it applies to events. I think an ideal system for this would be such that the tagging system is stored in the database, and an initial tagging system can be created; perhaps creating 10 different tags; but then there should be an admin option which enables a dynamically created tagging system. When the admin runs this, it should scour all the events in the system, and then create an admin specified number of tags which capture what events are in the system. Admins should also be able to manually add and edit tags; and should be able to instruct the system to auto-tag events using event sources, title, and description.

I would like for the front end of this app to be a React/Vite app. I would like for the backend of this app to be hosted in Supabase. Ideally much of the scraping can happen in Edge functions but it might also be necessary for there to be some of this functionality built into Python. It might be worth researching whether some of this should be done in n8n since it has great agentic functionality and can incorporate Python code write into it and is quite modular. The other option would be langchain, which might be a bit more complicated but could perhaps be built well into Supabase edge functions. I'd like to entertain the different possibilities here and have a good weighing of my options; including options I might be missing. 